{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## !! The final result should be only a runnable .py file !!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1099adc6448f5f46"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.utils.data import random_split\n",
    "from models import model_1 as m\n",
    "from training_early_stop import EarlyStop\n",
    "import utility"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T09:49:23.372568900Z",
     "start_time": "2023-10-24T09:49:21.972222400Z"
    }
   },
   "id": "aff6d85dd0096bd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Data Pre-processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "718fed71c402d1dc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # turn the graph to single color channel\n",
    "    transforms.Resize((227, 227)), # resize to 227 * 227 because we use AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # normalize\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    '../dataset/train', transform=data_transforms)\n",
    "# split training set to training set and validation set\n",
    "# a random seed to ensure reproducibility of results.\n",
    "torch.manual_seed(42)\n",
    "train_size = int(0.85 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = datasets.ImageFolder('../dataset/test', transform=data_transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024,shuffle=False, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=8, pin_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T09:49:50.028946300Z",
     "start_time": "2023-10-24T09:49:49.971072400Z"
    }
   },
   "id": "b8060e570dd48d1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65e424f66d1a2a74"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# initialize model, loss-function and optimizer\n",
    "model = m.EmotionCNN(num_classes=7)  # FER-2013 has 7 emotion class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T09:50:04.306607800Z",
     "start_time": "2023-10-24T09:50:04.057880100Z"
    }
   },
   "id": "ebf6186fa8daf7b8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA + cudnn\n"
     ]
    }
   ],
   "source": [
    "# select device\n",
    "device = utility.select_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T09:50:08.857581500Z",
     "start_time": "2023-10-24T09:50:08.817391200Z"
    }
   },
   "id": "6faa84704020905c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# average loss / epoch\n",
    "loss_history_per_epoch = []\n",
    "# correct prediction / epoch\n",
    "correct_prediction_pre_epoch = []\n",
    "# accuracy / epoch\n",
    "accuracy_per_epoch = []\n",
    "# validation loss\n",
    "val_loss_per_epoch = []\n",
    "# validation accuracy\n",
    "val_accuracy_per_epoch = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T09:50:13.292737500Z",
     "start_time": "2023-10-24T09:50:13.285217600Z"
    }
   },
   "id": "e20234f5835cb7e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training model\n",
    "num_epochs = 1000\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# early stopping variables\n",
    "stopping_count = 100\n",
    "different = 0.001\n",
    "interval = 5\n",
    "counter = 0\n",
    "is_always = False\n",
    "is_exe = False\n",
    "early_stopping = EarlyStop(m.pth_save_path, stopping_count, different)\n",
    "\n",
    "# progress bar\n",
    "process = tqdm(range(num_epochs), bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}', colour='green', ascii='░▒█', unit='epoch')\n",
    "\n",
    "for epoch in process:\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # forwarding get output\n",
    "        outputs = model(inputs)\n",
    "        # compute loss of output\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record training status\n",
    "        running_loss += loss.item()\n",
    "        prediction = outputs.argmax(dim=1)\n",
    "        num_correct_prediction = (prediction == labels).sum().item()\n",
    "        correct_prediction_pre_epoch.append(num_correct_prediction)\n",
    "        accuracy += num_correct_prediction / inputs.shape[0]\n",
    "    # save training status\n",
    "    loss_history_per_epoch.append((running_loss / len(train_loader)))\n",
    "    accuracy_per_epoch.append((accuracy / len(train_loader)))\n",
    "\n",
    "    # training validation + early stopping\n",
    "    if is_always or is_exe or (epoch!=0 and epoch%(interval-1)==0):\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "\n",
    "        if epoch%(interval-1)==0:\n",
    "            early_stopping.counter = 0\n",
    "            early_stopping.best_loss = None\n",
    "            is_exe = True\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        if counter >= stopping_count:\n",
    "            counter = 0\n",
    "            is_exe = False\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            prediction = outputs.argmax(dim=1)\n",
    "            num_correct_prediction = (prediction == labels).sum().item()\n",
    "            accuracy = num_correct_prediction / inputs.shape[0]\n",
    "            val_accuracy += accuracy\n",
    "        val_loss_per_epoch.append((val_loss / len(val_loader)))\n",
    "        val_accuracy_per_epoch.append((val_accuracy / len(val_loader)))\n",
    "\n",
    "        early_stopping.check_status(model, val_loss)\n",
    "\n",
    "        # display recently 5 average loss of epochs\n",
    "        process.set_description(f\"avg loss[-5:] = {loss_history_per_epoch[-5:]}\\t\"\n",
    "                                f\"accuracy[-5:] = {accuracy_per_epoch[-5:]}\\t\"\n",
    "                                f\"best loss = {early_stopping.min_val_loss}, val loss = {val_loss}\\t\"\n",
    "                                f\"val accuracy[-5] = {val_accuracy_per_epoch[-5:]}\\t\"\n",
    "                                f\"Stop Counter = {early_stopping.counter}/{stopping_count}\\t\")\n",
    "    else:\n",
    "        process.set_description(f\"avg loss[-5:] = {loss_history_per_epoch[-5:]}\\t\"\n",
    "                                f\"accuracy[-5:] = {accuracy_per_epoch[-5:]}\\t\")\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print('\\nTrigger Early Stopping\\n')\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbee02adc11f36ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the pth file\n",
    "torch.save(model.state_dict(), m.pth_manual_save_path)\n",
    "\n",
    "utility.save_pickle_files(loss_history_per_epoch, m.record_save_path + '/loss_history.pkl')\n",
    "utility.save_pickle_files(accuracy_per_epoch, m.record_save_path + '/accuracy_history.pkl')\n",
    "utility.save_pickle_files(val_loss_per_epoch, m.record_save_path + '/val_loss_history.pkl')\n",
    "utility.save_pickle_files(val_accuracy_per_epoch, m.record_save_path + '/val_accuracy_history.pkl.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693c80bd33607ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "model = m.EmotionCNN(num_classes=7)\n",
    "utility.model_validation(model, device, test_loader, m.pth_save_path)\n",
    "utility.model_validation(model, device, test_loader, m.pth_manual_save_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "834c051e833e8399"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
