{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6d85dd0096bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T13:15:13.028812700Z",
     "start_time": "2023-10-29T13:15:07.866529600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.utils.data import random_split\n",
    "import models.optimizer.optimizer as optimizer\n",
    "from models.old import Customized_cnn_ELU as m\n",
    "from helper.training_early_stop import EarlyStop\n",
    "import helper.utility as utility\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718fed71c402d1dc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 0. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8060e570dd48d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T13:15:14.770017100Z",
     "start_time": "2023-10-29T13:15:14.616311500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # normalize\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    '../dataset/train', transform=data_transforms)\n",
    "# split training set to training set and validation set\n",
    "# a random seed to ensure reproducibility of results.\n",
    "torch.manual_seed(42)\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = datasets.ImageFolder('../dataset/test', transform=data_transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64,shuffle=False, num_workers=16, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=16, pin_memory=False)\n",
    "\n",
    "print(len(val_loader), len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa84704020905c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T13:15:17.131429600Z",
     "start_time": "2023-10-29T13:15:15.514855400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select device\n",
    "device = utility.select_devices(use_cudnn_if_avaliable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e424f66d1a2a74",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20234f5835cb7e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T13:15:18.984362700Z",
     "start_time": "2023-10-29T13:15:18.974628800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Be used to compare results.\n",
    "\n",
    "# average loss / epoch\n",
    "loss_history_per_epoch = []\n",
    "# correct prediction / epoch\n",
    "correct_prediction_pre_epoch = []\n",
    "# accuracy / epoch\n",
    "accuracy_per_epoch = []\n",
    "# validation loss\n",
    "val_loss_per_epoch = []\n",
    "# validation accuracy\n",
    "val_accuracy_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6186fa8daf7b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T13:15:21.786134600Z",
     "start_time": "2023-10-29T13:15:21.167427600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# todo: select optimizer\n",
    "optimizer_name = \"Adam_amsgrad\"\n",
    "# optimizer_name = \"SGD\"\n",
    "\n",
    "# saving path\n",
    "m.model_name += m.model_name + optimizer_name\n",
    "m.pth_save_path = './model_data/' + m.model_name + '/model.pth'\n",
    "m.pth_manual_save_path = './model_data/' + \\\n",
    "    m.model_name + '/manual_save_model.pth'\n",
    "m.record_save_path = './model_data/' + m.model_name\n",
    "\n",
    "# initialize model, loss-function and optimizer\n",
    "model = m.EmotionCNN(num_classes=7)  # FER-2013 has 7 emotion class\n",
    "if not os.path.exists(m.record_save_path):\n",
    "    os.makedirs(m.record_save_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer.create_optimizer(model.parameters(), optimizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e3ae3eea3ff84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:54:19.873112300Z",
     "start_time": "2023-10-24T19:54:19.681970800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# less: num_epochs, stop_counter_interval, different\n",
    "# more: stop_counter\n",
    "\n",
    "# training model\n",
    "num_epochs = 500\n",
    "\n",
    "# early stopping variables\n",
    "stop_counter = 18 # number of count to trigger early stop (patience)\n",
    "stop_counter_window = stop_counter + 5 # a range to check stop_counter\n",
    "different = 0.00008 # different between the best val loss and the most recent one\n",
    "stop_counter_interval = 10 # check for early stop for every stop_counter_interval\n",
    "counter = 0 # number of count for every trail of early stop\n",
    "is_always = True # always check for early stop, set to true will ignore other setting except stop_counter\n",
    "is_exe = False # is early stop running\n",
    "run_after = 0\n",
    "early_stopping = EarlyStop(m.pth_save_path, stop_counter, different, type=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8472fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLRonPlateau (which can improve lr every epoch)\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',                 # 'max' for monitoring validation accuracy\n",
    "    factor=0.4,                 # factor by which the learning rate will be reduced\n",
    "    patience=6,                 # number of epochs with no improvement to trigger LR reduction\n",
    "    min_lr=1e-7,                # minimum learning rate\n",
    "    verbose=1                   # (1: print messages, 0: not print message)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee02adc11f36ba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T19:54:20.915057500Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "# progress bar\n",
    "process = tqdm(range(num_epochs), bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}', colour='green', unit='epoch')\n",
    "\n",
    "for epoch in process:\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    model.train()\n",
    "\n",
    "    # Loop over the training data in batches\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # forwarding get output\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # compute loss of output\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record training status\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # calculate accuracy\n",
    "        probability = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        max_probability, prediction = torch.max(probability, dim=1)\n",
    "        num_correct_prediction = (prediction == labels).sum().item()\n",
    "        accuracy += num_correct_prediction / inputs.shape[0]\n",
    "        correct_prediction_pre_epoch.append(num_correct_prediction)\n",
    "\n",
    "    # save training status\n",
    "    loss_history_per_epoch.append((running_loss / len(train_loader)))\n",
    "    accuracy_per_epoch.append((accuracy / len(train_loader)))\n",
    "\n",
    "    # training validation + early stopping\n",
    "    if epoch >= run_after and (is_always or is_exe or epoch % stop_counter_interval == 0):\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "\n",
    "        if not is_always and epoch % stop_counter_interval ==0:\n",
    "            early_stopping.counter = 0\n",
    "            is_exe = True\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        if not is_always and counter >= stop_counter_window:\n",
    "            counter = 0\n",
    "            is_exe = False\n",
    "\n",
    "        model.eval() # set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # calculate validation accuracy\n",
    "                probability = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                max_probability, prediction = torch.max(probability, dim=1)\n",
    "                num_correct_prediction = (prediction == labels).sum().item()\n",
    "                accuracy = num_correct_prediction / inputs.shape[0]\n",
    "                val_accuracy += accuracy\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_accuracy / len(val_loader)\n",
    "        val_loss_per_epoch.append(val_loss)\n",
    "        val_accuracy_per_epoch.append(val_accuracy)\n",
    "\n",
    "        # check the early stopping status\n",
    "        early_stopping.check_status(model, val_accuracy)\n",
    "\n",
    "        # at the end of each epoch, update the learning rate\n",
    "        lr_scheduler.step(val_accuracy)\n",
    "\n",
    "        # display recently 5 average loss of epochs\n",
    "        process.set_description(f\"avg loss[-5:] = {['{:.5f}'.format(num) for num in loss_history_per_epoch[-5:]]}\\t\"\n",
    "                                f\"val loss[-5:] = {['{:.5f}'.format(num) for num in val_loss_per_epoch[-5:]]}\\t\"\n",
    "                                f\"accuracy[-5:] = {['{:.5f}'.format(num) for num in accuracy_per_epoch[-5:]]}\\t\"\n",
    "                                f\"val accuracy[-5:] = {['{:.5f}'.format(num) for num in val_accuracy_per_epoch[-5:]]}\\t\"\n",
    "                                f\"best value = {'{:.5f}'.format(early_stopping.best_of_all_value)}\\t\"\n",
    "                                f\"Counter = {early_stopping.counter}/{stop_counter} | {counter}/{stop_counter_window}\\t\")\n",
    "    else:\n",
    "        process.set_description(f\"avg loss[-5:] = {['{:.5f}'.format(num) for num in loss_history_per_epoch[-5:]]}\\t\"\n",
    "                                f\"accuracy[-5:] = {['{:.5f}'.format(num) for num in accuracy_per_epoch[-5:]]}\\t\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if early_stopping.early_stop:\n",
    "        print('\\nTrigger Early Stopping\\n')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edf735",
   "metadata": {},
   "source": [
    "# 2. Save model and records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c80bd33607ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T18:17:56.660178700Z",
     "start_time": "2023-10-24T18:17:55.664185Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the pth file\n",
    "torch.save(model.state_dict(), m.pth_manual_save_path)\n",
    "\n",
    "utility.save_pickle_files(loss_history_per_epoch, m.record_save_path + '/loss_history.pkl')\n",
    "utility.save_pickle_files(accuracy_per_epoch, m.record_save_path + '/accuracy_history.pkl')\n",
    "utility.save_pickle_files(val_loss_per_epoch, m.record_save_path + '/val_loss_history.pkl')\n",
    "utility.save_pickle_files(val_accuracy_per_epoch, m.record_save_path + '/val_accuracy_history.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab39d7b",
   "metadata": {},
   "source": [
    "# 3. Plot records and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ed9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graphs\n",
    "data = utility.read_pickle_files(m.record_save_path + '/loss_history.pkl')\n",
    "utility.plot_record(x=range(len(data)), y=data, xlabel=\"epoch\", ylabel=\"loss\", title=\"Training Loss\", \n",
    "                    save_path=m.record_save_path+\"/loss_history.png\")\n",
    "\n",
    "data = utility.read_pickle_files(m.record_save_path + '/accuracy_history.pkl')\n",
    "utility.plot_record(x=range(len(data)), y=data, xlabel=\"epoch\", ylabel=\"accuracy\", title=\"Training Accuracy\", \n",
    "                    save_path=m.record_save_path+\"/accuracy_history.png\")\n",
    "\n",
    "data = utility.read_pickle_files(m.record_save_path + '/val_loss_history.pkl')\n",
    "utility.plot_record(x=range(len(data)), y=data, xlabel=\"epoch\", ylabel=\"validation loss\", \n",
    "                    title=\"Validation Loss\", save_path=m.record_save_path+\"/val_loss_history.png\")\n",
    "\n",
    "data = utility.read_pickle_files(m.record_save_path + '/val_accuracy_history.pkl')\n",
    "utility.plot_record(x=range(len(data)), y=data, xlabel=\"epoch\", ylabel=\"validation accuracy\", \n",
    "                    title=\"Validation Accuracy\", save_path=m.record_save_path+\"/val_accuracy_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c051e833e8399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T18:18:22.800739800Z",
     "start_time": "2023-10-24T18:17:56.660682200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "model = m.EmotionCNN(num_classes=7)\n",
    "utility.model_validation(model, device, test_loader, m.pth_save_path, m.record_save_path)\n",
    "utility.model_validation(model, device, test_loader, m.pth_manual_save_path, m.record_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398b1ba27997308",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
