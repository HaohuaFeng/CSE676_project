{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !! The final result should be only a runnable .py file !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T00:43:34.718281800Z",
     "start_time": "2023-10-22T00:43:34.714770600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T22:10:31.247500200Z",
     "start_time": "2023-10-21T22:10:31.185193300Z"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # turn the graph to single color channel\n",
    "    transforms.Resize((227, 227)), # resize to 227 * 227 because we use AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # normalize\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    '../dataset/train', transform=data_transforms)\n",
    "# split training set to training set and validation set\n",
    "# set a random seed to ensure reproducibility of results.\n",
    "torch.manual_seed(42)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = datasets.ImageFolder('../dataset/test', transform=data_transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512,shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T22:10:38.504027800Z",
     "start_time": "2023-10-21T22:10:38.073359500Z"
    }
   },
   "outputs": [],
   "source": [
    "# todo: we should compare the optimal version with the previous ones\n",
    "# version optimal\n",
    "# reference: AlexNet\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=2), \n",
    "            # out_channels is decided by # of filters\n",
    "            # batch_size doesn't show here and is different from in_channels.\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True), # inplace: override\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # output shape: (batch_size, channels = 256, height = 6, width = 6)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.flatten = nn.Flatten(1) \n",
    "        # flatten from channel, ex: [batch_size, channels(1), height, width] -> [batch_size, channels * height * width]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x # the probability of 7 emotion class\n",
    "    \n",
    "\n",
    "# initialize model, loss-function and optimizer\n",
    "model = EmotionCNN(num_classes=7)  # FER-2013 has 7 emotion class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T22:10:39.069220100Z",
     "start_time": "2023-10-21T22:10:39.062970300Z"
    }
   },
   "outputs": [],
   "source": [
    "# select device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"using cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#    print(\"using mac mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T00:42:00.294274500Z",
     "start_time": "2023-10-21T22:10:40.349987900Z"
    }
   },
   "outputs": [],
   "source": [
    "# training model\n",
    "num_epochs = 500\n",
    "model.to(device)\n",
    "\n",
    "# some data structures to record data\n",
    "loss_history = []\n",
    "\n",
    "# early stopping variables\n",
    "early_stopping_patience = 10 # patience for telerating epochs witout improvment\n",
    "early_stopping_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "# progress bar\n",
    "process = tqdm(range(num_epochs), bar_format='{l_bar}{bar:25}{r_bar}{bar:-25b}', colour='green', ascii='░▒█', unit='epoch')\n",
    "\n",
    "for epoch in process:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = f\"{(running_loss / len(train_loader)):5f}\"\n",
    "    loss_history.append(avg_loss)\n",
    "    process.set_description(f\"loss[-5:] = {loss_history[-5:]}\")\n",
    "    # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    ## ===  Early Stopping  === ##\n",
    "    # evaluate the model's performance on the validation set after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:  # load val_loader to evaluate training performance\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # to see whether the performance of this epoch is better than the privious one or not\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    # if there is no improvement in performance for early_stopping_patience consecutive epochs, then stop training.\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping: No improvement in validation loss for {} epochs.\".format(\n",
    "            early_stopping_patience))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T00:42:20.316765400Z",
     "start_time": "2023-10-22T00:42:19.434997100Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the pth file\n",
    "torch.save(best_model_state, '8FC 00025LR emotion_cnn.pth')\n",
    "\n",
    "with open('train_loss_history_8FC.pkl', 'wb') as f:\n",
    "    pickle.dump(loss_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T00:45:52.212885200Z",
     "start_time": "2023-10-22T00:45:52.208816100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T00:46:26.147261600Z",
     "start_time": "2023-10-22T00:46:12.412622300Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "\n",
    "model = EmotionCNN(num_classes=7)\n",
    "model.load_state_dict(torch.load('emotion_cnn.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1) # predicted is the emotion index\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
